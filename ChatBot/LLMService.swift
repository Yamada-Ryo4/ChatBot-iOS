import Foundation

// è¿™æ˜¯ä¸€ä¸ªçº¯é€»è¾‘æœåŠ¡ï¼Œä¸æ¶‰åŠ UIï¼Œæ‰€ä»¥ä¸è¦åŠ  @MainActor
class LLMService: NSObject {
    
    private lazy var session: URLSession = {
        let config = URLSessionConfiguration.default
        config.timeoutIntervalForRequest = 120.0  // è¯·æ±‚è¶…æ—¶ 120ç§’
        config.timeoutIntervalForResource = 300.0 // èµ„æºè¶…æ—¶ 5åˆ†é’Ÿ
        config.waitsForConnectivity = true        // ç­‰å¾…ç½‘ç»œè¿æ¥
        return URLSession(configuration: config) // âš ï¸ ç§»é™¤ delegateï¼Œæ¢å¤ç³»ç»Ÿé»˜è®¤å®‰å…¨éªŒè¯
    }()
    
    // ç§»é™¤æ‰‹åŠ¨ TLS éªŒè¯ä»£ç†æ–¹æ³•ï¼Œå› ä¸ºæœåŠ¡å™¨è¯ä¹¦ç»è¿‡éªŒè¯æ˜¯åˆæ³•çš„ Let's Encrypt è¯ä¹¦
    // åŒæ—¶ä¹Ÿç§»é™¤äº†å¯èƒ½å¯¼è‡´ HTTP/2 æ¡æ‰‹é—®é¢˜çš„å¹²æ‰°


    func fetchModels(config: ProviderConfig) async throws -> [AIModelInfo] {
        switch config.apiType {
        case .openAI, .openAIResponses: return try await fetchOpenAIModels(baseURL: config.baseURL, apiKey: config.apiKey)
        case .gemini: return try await fetchGeminiModels(baseURL: config.baseURL, apiKey: config.apiKey)
        case .anthropic: return try await fetchAnthropicModels(baseURL: config.baseURL, apiKey: config.apiKey)
        case .workersAI: return [] // Workers AI æ— æ¨¡å‹åˆ—è¡¨æ¥å£
        }
    }

    func streamChat(messages: [ChatMessage], modelId: String, config: ProviderConfig, temperature: Double = 0.7) -> AsyncThrowingStream<String, Error> {
        switch config.apiType {
        case .openAI: return streamOpenAIChat(messages: messages, modelId: modelId, baseURL: config.baseURL, apiKey: config.apiKey, temperature: temperature)
        case .gemini: return streamGeminiChat(messages: messages, modelId: modelId, baseURL: config.baseURL, apiKey: config.apiKey, temperature: temperature)
        case .openAIResponses: return streamOpenAIResponses(messages: messages, modelId: modelId, baseURL: config.baseURL, apiKey: config.apiKey, temperature: temperature)
        case .anthropic: return streamAnthropicChat(messages: messages, modelId: modelId, baseURL: config.baseURL, apiKey: config.apiKey, temperature: temperature)
        case .workersAI: return streamOpenAIChat(messages: messages, modelId: modelId, baseURL: config.baseURL, apiKey: config.apiKey, temperature: temperature)
        }
    }
    
    // MARK: - v1.7: Embedding API
    
    func fetchEmbedding(text: String, modelId: String, config: ProviderConfig, dimensions: Int? = nil) async throws -> [Float] {
        switch config.apiType {
        case .openAI, .openAIResponses:
            return try await fetchOpenAIEmbedding(text: text, modelId: modelId, baseURL: config.baseURL, apiKey: config.apiKey, dimensions: dimensions)
        case .gemini:
            return try await fetchGeminiEmbedding(text: text, modelId: modelId, baseURL: config.baseURL, apiKey: config.apiKey, dimensions: dimensions)
        case .workersAI:
            return try await fetchWorkersAIEmbedding(text: text, baseURL: config.baseURL)
        case .anthropic:
            throw NSError(domain: "Embedding", code: -1, userInfo: [NSLocalizedDescriptionKey: "Anthropic ä¸æ”¯æŒ Embedding API"])
        }
    }
    
    // MARK: - Workers AI Embedding
    
    private func fetchWorkersAIEmbedding(text: String, baseURL: String) async throws -> [Float] {
        let urlString = baseURL.hasPrefix("http") ? baseURL : "https://\(baseURL)"
        guard let url = URL(string: urlString) else { throw URLError(.badURL) }
        
        var request = URLRequest(url: url)
        request.httpMethod = "POST"
        request.setValue("application/json", forHTTPHeaderField: "Content-Type")
        request.httpBody = try? JSONSerialization.data(withJSONObject: ["text": text])
        
        let (data, _) = try await session.data(for: request)
        guard let json = try? JSONSerialization.jsonObject(with: data) as? [String: Any],
              let dataArr = json["data"] as? [[Double]],
              let first = dataArr.first else {
            if let json = try? JSONSerialization.jsonObject(with: data) as? [String: Any],
               let error = json["error"] as? String {
                throw NSError(domain: "Embedding", code: -1, userInfo: [NSLocalizedDescriptionKey: error])
            }
            throw NSError(domain: "Embedding", code: -1, userInfo: [NSLocalizedDescriptionKey: "æ— æ³•è§£æ Workers AI å“åº”"])
        }
        return first.map { Float($0) }
    }
    
    private func fetchOpenAIEmbedding(text: String, modelId: String, baseURL: String, apiKey: String, dimensions: Int? = nil) async throws -> [Float] {
        guard let req = buildRequest(baseURL: baseURL, path: "embeddings", apiKey: apiKey, type: .openAI) else {
            throw URLError(.badURL)
        }
        var request = req
        request.httpMethod = "POST"
        var body: [String: Any] = ["model": modelId, "input": text]
        if let dim = dimensions { body["dimensions"] = dim }
        request.httpBody = try? JSONSerialization.data(withJSONObject: body)
        
        let (data, _) = try await session.data(for: request)
        guard let json = try? JSONSerialization.jsonObject(with: data) as? [String: Any],
              let dataArr = json["data"] as? [[String: Any]],
              let first = dataArr.first,
              let embedding = first["embedding"] as? [Double] else {
            // æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯ä¿¡æ¯
            if let json = try? JSONSerialization.jsonObject(with: data) as? [String: Any],
               let error = json["error"] as? [String: Any],
               let message = error["message"] as? String {
                throw NSError(domain: "Embedding", code: -1, userInfo: [NSLocalizedDescriptionKey: message])
            }
            throw NSError(domain: "Embedding", code: -1, userInfo: [NSLocalizedDescriptionKey: "æ— æ³•è§£æ Embedding å“åº”"])
        }
        return embedding.map { Float($0) }
    }
    
    private func fetchGeminiEmbedding(text: String, modelId: String, baseURL: String, apiKey: String, dimensions: Int? = nil) async throws -> [Float] {
        let path = "models/\(modelId):embedContent"
        guard let req = buildRequest(baseURL: baseURL, path: path, apiKey: apiKey, type: .gemini) else {
            throw URLError(.badURL)
        }
        var request = req
        request.httpMethod = "POST"
        var body: [String: Any] = [
            "model": "models/\(modelId)",
            "content": ["parts": [["text": text]]]
        ]
        if let dim = dimensions { body["outputDimensionality"] = dim }
        request.httpBody = try? JSONSerialization.data(withJSONObject: body)
        
        let (data, _) = try await session.data(for: request)
        guard let json = try? JSONSerialization.jsonObject(with: data) as? [String: Any],
              let embeddingObj = json["embedding"] as? [String: Any],
              let values = embeddingObj["values"] as? [Double] else {
            if let json = try? JSONSerialization.jsonObject(with: data) as? [String: Any],
               let error = json["error"] as? [String: Any],
               let message = error["message"] as? String {
                throw NSError(domain: "Embedding", code: -1, userInfo: [NSLocalizedDescriptionKey: message])
            }
            throw NSError(domain: "Embedding", code: -1, userInfo: [NSLocalizedDescriptionKey: "æ— æ³•è§£æ Gemini Embedding å“åº”"])
        }
        return values.map { Float($0) }
    }
    
    // MARK: - Implementations
    private func fetchOpenAIModels(baseURL: String, apiKey: String) async throws -> [AIModelInfo] {
        guard let request = buildRequest(baseURL: baseURL, path: "models", apiKey: apiKey, type: .openAI) else { throw URLError(.badURL) }
        
        // ä½¿ç”¨ legacyData 
        let (data, response) = try await legacyData(for: request)
        try validateResponse(response, data: data)
        // ä½¿ç”¨æ–‡ä»¶åº•éƒ¨çš„ç§æœ‰ç»“æ„ä½“è§£æ
        let list = try JSONDecoder().decode(PrivateOpenAIModelListResponse.self, from: data)
        return list.data.map { AIModelInfo(id: $0.id, displayName: nil) }.sorted { $0.id < $1.id }
    }
    
    private func fetchGeminiModels(baseURL: String, apiKey: String) async throws -> [AIModelInfo] {
        guard let request = buildRequest(baseURL: baseURL, path: "models", apiKey: apiKey, type: .gemini) else { throw URLError(.badURL) }
        let (data, response) = try await legacyData(for: request)
        try validateResponse(response, data: data)
        let list = try JSONDecoder().decode(PrivateGeminiModelListResponse.self, from: data)
        return list.models.map { m in
            let shortID = m.name.replacingOccurrences(of: "models/", with: "")
            return AIModelInfo(id: shortID, displayName: nil)
        }.filter { $0.id.contains("gemini") }.sorted { $0.id < $1.id }
    }
    
    private func streamOpenAIChat(messages: [ChatMessage], modelId: String, baseURL: String, apiKey: String, temperature: Double) -> AsyncThrowingStream<String, Error> {
        return AsyncThrowingStream { continuation in
            let task = Task {
                var isReasoning = false // v1.13: è®°å½• OpenAI å…¼å®¹æµä¸­æ˜¯å¦å¤„äºæ¨ç†é˜¶æ®µ
                
                let openAIMessages: [[String: Any]] = messages.map { msg in
                    var content: Any = msg.text
                    if let imgData = msg.imageData {
                        content = [["type": "text", "text": msg.text], ["type": "image_url", "image_url": ["url": "data:image/jpeg;base64,\(imgData.base64EncodedString())"]]]
                    }
                    return ["role": msg.role.rawValue, "content": content]
                }
                let body: [String: Any] = ["model": modelId, "messages": openAIMessages, "stream": true, "temperature": temperature]
                guard var req = buildRequest(baseURL: baseURL, path: "chat/completions", apiKey: apiKey, type: .openAI) else { continuation.finish(throwing: URLError(.badURL)); return }
                req.httpMethod = "POST"
                req.httpBody = try? JSONSerialization.data(withJSONObject: body)
                await performStream(request: req, continuation: continuation) { line in
                    guard line.hasPrefix("data: ") else {
                        // é data: å¼€å¤´çš„è¡Œï¼Œå¯èƒ½æ˜¯å…¶ä»–æ ¼å¼
                        let trimmed = line.trimmingCharacters(in: .whitespacesAndNewlines)
                        if !trimmed.isEmpty && trimmed != "" {
                            print("âš ï¸ OpenAI éæ ‡å‡†è¡Œ: \(line.prefix(200))")
                            return "[RAW] " + line
                        }
                        return nil
                    }
                    let json = String(line.dropFirst(6))
                    if json.trimmingCharacters(in: .whitespaces) == "[DONE]" { return nil }
                    
                    // å°è¯•æ ‡å‡† OpenAI æ ¼å¼è§£æ
                    if let data = json.data(using: .utf8), let res = try? JSONDecoder().decode(PrivateOpenAIStreamResponse.self, from: data) {
                        let delta = res.choices.first?.delta
                        var result = ""
                        
                        // v1.13: å®Œç¾åŒ…è£¹ reasoning_content
                        if let reasoning = delta?.reasoning_content, !reasoning.isEmpty {
                            if !isReasoning {
                                result += "<think>\n"
                                isReasoning = true
                            }
                            result += reasoning
                        } else if let content = delta?.content, !content.isEmpty {
                            if isReasoning {
                                result += "\n</think>\n"
                                isReasoning = false
                            }
                            result += content
                        }
                        return result.isEmpty ? nil : result
                    }
                    
                    // è§£æå¤±è´¥ï¼Œå°è¯•é€šç”¨ JSON è§£æ
                    if let data = json.data(using: .utf8),
                       let dict = try? JSONSerialization.jsonObject(with: data) as? [String: Any] {
                        // å°è¯•æå–å¸¸è§å­—æ®µ
                        if let error = dict["error"] as? [String: Any], let message = error["message"] as? String {
                            return "âŒ APIé”™è¯¯: " + message
                        }
                        // å…¶ä»–æ ¼å¼ï¼šè¾“å‡ºåŸå§‹å†…å®¹
                        print("âš ï¸ OpenAI æœªçŸ¥æ ¼å¼: \(json.prefix(200))")
                        return "[DEBUG] " + json
                    }
                    
                    // å®Œå…¨æ— æ³•è§£æï¼Œè¿”å›åŸå§‹æ•°æ®
                    if !json.trimmingCharacters(in: .whitespacesAndNewlines).isEmpty {
                        print("âš ï¸ OpenAI è§£æå¤±è´¥: \(json.prefix(200))")
                        return "[PARSE_FAIL] " + json
                    }
                    return nil
                }
            }
            continuation.onTermination = { @Sendable _ in task.cancel() }
        }
    }
    
    private func streamGeminiChat(messages: [ChatMessage], modelId: String, baseURL: String, apiKey: String, temperature: Double) -> AsyncThrowingStream<String, Error> {
        return AsyncThrowingStream { continuation in
            let task = Task {
                let contents: [[String: Any]] = messages.map { msg in
                    var parts: [[String: Any]] = []
                    if let imgData = msg.imageData { parts.append(["inline_data": ["mime_type": "image/jpeg", "data": imgData.base64EncodedString()]]) }
                    if !msg.text.isEmpty { parts.append(["text": msg.text]) }
                    let role = (msg.role == .user) ? "user" : "model"
                    return ["role": role, "parts": parts]
                }
                let generationConfig: [String: Any] = ["temperature": temperature]
                
                // v1.7.1: æ”¾å®½å®‰å…¨é™åˆ¶ï¼Œé˜²æ­¢ "17å²" ç­‰å†…å®¹è¢«è¯¯æ‹¦æˆª
                let safetySettings: [[String: Any]] = [
                    ["category": "HARM_CATEGORY_HARASSMENT", "threshold": "BLOCK_NONE"],
                    ["category": "HARM_CATEGORY_HATE_SPEECH", "threshold": "BLOCK_NONE"],
                    ["category": "HARM_CATEGORY_SEXUALLY_EXPLICIT", "threshold": "BLOCK_NONE"],
                    ["category": "HARM_CATEGORY_DANGEROUS_CONTENT", "threshold": "BLOCK_NONE"]
                ]
                
                let body: [String: Any] = [
                    "contents": contents,
                    "generationConfig": generationConfig,
                    "safetySettings": safetySettings
                ]
                let path = "models/\(modelId):streamGenerateContent?alt=sse"
                
                guard var req = buildRequest(baseURL: baseURL, path: path, apiKey: apiKey, type: .gemini) else { continuation.finish(throwing: URLError(.badURL)); return }
                req.httpMethod = "POST"
                req.httpBody = try? JSONSerialization.data(withJSONObject: body)
                await performStream(request: req, continuation: continuation) { line in
                    guard line.hasPrefix("data: ") else {
                        let trimmed = line.trimmingCharacters(in: .whitespacesAndNewlines)
                        if !trimmed.isEmpty {
                            print("âš ï¸ Gemini éæ ‡å‡†è¡Œ: \(line.prefix(200))")
                            return "[RAW] " + line
                        }
                        return nil
                    }
                    let json = String(line.dropFirst(6))
                    
                    // å°è¯•æ ‡å‡† Gemini æ ¼å¼è§£æ
                    if let data = json.data(using: .utf8), let dict = try? JSONSerialization.jsonObject(with: data) as? [String: Any] {
                        // æ£€æŸ¥é”™è¯¯
                        if let error = dict["error"] as? [String: Any], let message = error["message"] as? String {
                            return "âŒ APIé”™è¯¯: " + message
                        }
                        // æ ‡å‡†æ ¼å¼
                        if let candidates = dict["candidates"] as? [[String: Any]],
                           let content = candidates.first?["content"] as? [String: Any],
                           let parts = content["parts"] as? [[String: Any]],
                           let text = parts.first?["text"] as? String {
                            // v1.13: å…¼å®¹ Gemini 3.0 Pro çš„å†…éƒ¨æ€è€ƒæ ‡ç­¾
                            // Gemini åŸç”Ÿåå‡ºçš„æ˜¯ <thought>ï¼Œæˆ‘ä»¬å°†å®ƒç»Ÿä¸€æ›¿æ¢ä¸º <think> å–‚ç»™å‰ç«¯çŠ¶æ€æœº
                            let standardizedText = text
                                .replacingOccurrences(of: "<thought>", with: "<think>")
                                .replacingOccurrences(of: "</thought>", with: "</think>")
                            return standardizedText
                        }
                        // æœªçŸ¥æ ¼å¼ï¼Œè¾“å‡ºåŸå§‹å†…å®¹
                        print("âš ï¸ Gemini æœªçŸ¥æ ¼å¼: \(json.prefix(200))")
                        return "[DEBUG] " + json
                    }
                    
                    // å®Œå…¨æ— æ³•è§£æ
                    if !json.trimmingCharacters(in: .whitespacesAndNewlines).isEmpty {
                        print("âš ï¸ Gemini è§£æå¤±è´¥: \(json.prefix(200))")
                        return "[PARSE_FAIL] " + json
                    }
                    return nil
                }
            }
            continuation.onTermination = { @Sendable _ in task.cancel() }
        }
    }
    
    // MARK: - Anthropic Models Fetch
    private func fetchAnthropicModels(baseURL: String, apiKey: String) async throws -> [AIModelInfo] {
        // Anthropic ä¸æä¾›æ¨¡å‹åˆ—è¡¨ APIï¼Œè¿”å›é¢„è®¾çš„æ¨¡å‹åˆ—è¡¨
        return [
            AIModelInfo(id: "claude-3-5-sonnet-20241022", displayName: "Claude 3.5 Sonnet"),
            AIModelInfo(id: "claude-3-5-haiku-20241022", displayName: "Claude 3.5 Haiku"),
            AIModelInfo(id: "claude-3-opus-20240229", displayName: "Claude 3 Opus"),
            AIModelInfo(id: "claude-3-sonnet-20240229", displayName: "Claude 3 Sonnet"),
            AIModelInfo(id: "claude-3-haiku-20240307", displayName: "Claude 3 Haiku")
        ]
    }
    
    // MARK: - OpenAI Responses API (æ–°æ ¼å¼)
    private func streamOpenAIResponses(messages: [ChatMessage], modelId: String, baseURL: String, apiKey: String, temperature: Double) -> AsyncThrowingStream<String, Error> {
        return AsyncThrowingStream { continuation in
            let task = Task {
                // æ„å»º input æ•°ç»„æ ¼å¼
                var inputItems: [[String: Any]] = []
                for msg in messages {
                    var item: [String: Any] = ["role": msg.role.rawValue]
                    if let imgData = msg.imageData {
                        // å¤šæ¨¡æ€å†…å®¹
                        item["content"] = [
                            ["type": "input_text", "text": msg.text],
                            ["type": "input_image", "image_url": "data:image/jpeg;base64,\(imgData.base64EncodedString())"]
                        ]
                    } else {
                        item["content"] = msg.text
                    }
                    inputItems.append(item)
                }
                
                let body: [String: Any] = [
                    "model": modelId,
                    "input": inputItems,
                    "stream": true,
                    "temperature": temperature
                ]
                
                guard var req = buildRequest(baseURL: baseURL, path: "responses", apiKey: apiKey, type: .openAIResponses) else {
                    continuation.finish(throwing: URLError(.badURL))
                    return
                }
                req.httpMethod = "POST"
                req.httpBody = try? JSONSerialization.data(withJSONObject: body)
                
                await performStream(request: req, continuation: continuation) { line in
                    guard line.hasPrefix("data: ") else {
                        let trimmed = line.trimmingCharacters(in: .whitespacesAndNewlines)
                        if !trimmed.isEmpty && trimmed != "" {
                            print("âš ï¸ OpenAI Responses éæ ‡å‡†è¡Œ: \(line.prefix(200))")
                            return "[RAW] " + line
                        }
                        return nil
                    }
                    let json = String(line.dropFirst(6))
                    if json.trimmingCharacters(in: .whitespaces) == "[DONE]" { return nil }
                    
                    if let data = json.data(using: .utf8),
                       let dict = try? JSONSerialization.jsonObject(with: data) as? [String: Any] {
                        // æ£€æŸ¥é”™è¯¯
                        if let error = dict["error"] as? [String: Any], let message = error["message"] as? String {
                            return "âŒ APIé”™è¯¯: " + message
                        }
                        
                        // è§£æ response.output_text.delta äº‹ä»¶
                        if let eventType = dict["type"] as? String {
                            if eventType == "response.output_text.delta" {
                                if let delta = dict["delta"] as? String { return delta }
                            }
                            // å¤„ç†æ€è€ƒå†…å®¹ (å¦‚æœæœ‰)
                            if eventType == "response.reasoning.delta" {
                                if let delta = dict["delta"] as? String { return "ğŸ§ THINK:" + delta }
                            }
                        }
                        
                        // å…¼å®¹æ—§çš„ choices æ ¼å¼ (æŸäº›å…¼å®¹ API å¯èƒ½ä½¿ç”¨)
                        if let choices = dict["choices"] as? [[String: Any]],
                           let delta = choices.first?["delta"] as? [String: Any],
                           let content = delta["content"] as? String {
                            return content
                        }
                    }
                    return nil
                }
            }
            continuation.onTermination = { @Sendable _ in task.cancel() }
        }
    }
    
    // MARK: - Anthropic Messages API
    private func streamAnthropicChat(messages: [ChatMessage], modelId: String, baseURL: String, apiKey: String, temperature: Double) -> AsyncThrowingStream<String, Error> {
        return AsyncThrowingStream { continuation in
            let task = Task {
                // åˆ†ç¦» system æ¶ˆæ¯å’Œå…¶ä»–æ¶ˆæ¯
                var systemPrompt = ""
                var anthropicMessages: [[String: Any]] = []
                
                for msg in messages {
                    if msg.role == .system {
                        systemPrompt += (systemPrompt.isEmpty ? "" : "\n") + msg.text
                        continue
                    }
                    
                    let role = msg.role == .user ? "user" : "assistant"
                    var content: Any
                    
                    if let imgData = msg.imageData {
                        // å¤šæ¨¡æ€å†…å®¹
                        content = [
                            ["type": "image", "source": [
                                "type": "base64",
                                "media_type": "image/jpeg",
                                "data": imgData.base64EncodedString()
                            ]],
                            ["type": "text", "text": msg.text]
                        ]
                    } else {
                        content = msg.text
                    }
                    anthropicMessages.append(["role": role, "content": content])
                }
                
                var body: [String: Any] = [
                    "model": modelId,
                    "messages": anthropicMessages,
                    "max_tokens": 4096,
                    "stream": true,
                    "temperature": temperature
                ]
                if !systemPrompt.isEmpty {
                    body["system"] = systemPrompt
                }
                
                guard var req = buildRequest(baseURL: baseURL, path: "messages", apiKey: apiKey, type: .anthropic) else {
                    continuation.finish(throwing: URLError(.badURL))
                    return
                }
                req.httpMethod = "POST"
                req.httpBody = try? JSONSerialization.data(withJSONObject: body)
                
                await performStream(request: req, continuation: continuation) { line in
                    guard line.hasPrefix("data: ") else {
                        // å¤„ç† event: è¡Œï¼ˆAnthropic SSE æ ¼å¼ï¼‰
                        if line.hasPrefix("event: ") { return nil }
                        let trimmed = line.trimmingCharacters(in: .whitespacesAndNewlines)
                        if !trimmed.isEmpty && trimmed != "" {
                            print("âš ï¸ Anthropic éæ ‡å‡†è¡Œ: \(line.prefix(200))")
                        }
                        return nil
                    }
                    let json = String(line.dropFirst(6))
                    
                    if let data = json.data(using: .utf8),
                       let dict = try? JSONSerialization.jsonObject(with: data) as? [String: Any] {
                        // æ£€æŸ¥é”™è¯¯
                        if let error = dict["error"] as? [String: Any], let message = error["message"] as? String {
                            return "âŒ APIé”™è¯¯: " + message
                        }
                        
                        // è§£æäº‹ä»¶ç±»å‹
                        if let eventType = dict["type"] as? String {
                            switch eventType {
                            case "content_block_delta":
                                if let delta = dict["delta"] as? [String: Any] {
                                    // text delta
                                    if let text = delta["text"] as? String {
                                        return text
                                    }
                                    // thinking delta (Claude æ€è€ƒæ¨¡å¼)
                                    if let thinking = delta["thinking"] as? String {
                                        return "ğŸ§ THINK:" + thinking
                                    }
                                }
                            case "message_stop", "message_delta":
                                return nil
                            case "error":
                                if let error = dict["error"] as? [String: Any],
                                   let message = error["message"] as? String {
                                    return "âŒ " + message
                                }
                            default:
                                break
                            }
                        }
                    }
                    return nil
                }
            }
            continuation.onTermination = { @Sendable _ in task.cancel() }
        }
    }

    private func validateResponse(_ response: URLResponse?, data: Data) throws {
        guard let httpResponse = response as? HTTPURLResponse else { return }
        if httpResponse.statusCode != 200 {
            let errorBody = String(data: data, encoding: .utf8) ?? "No body"
            let msg = "HTTP \(httpResponse.statusCode) - \(errorBody.prefix(100))"
            print("âŒ API Error: \(msg) | URL: \(httpResponse.url?.absoluteString ?? "")")
            throw NSError(domain: "APIError", code: httpResponse.statusCode, userInfo: [NSLocalizedDescriptionKey: msg])
        }
    }
    
    private func buildRequest(baseURL: String, path: String, apiKey: String, type: APIType) -> URLRequest? {
        var cleanBase = baseURL.trimmingCharacters(in: .whitespacesAndNewlines)
        if cleanBase.hasSuffix("/") { cleanBase = String(cleanBase.dropLast()) }
        var fullPath = ""
        switch type {
        case .openAI, .openAIResponses, .workersAI: fullPath = "\(cleanBase)/\(path)"
        case .gemini:
            if cleanBase.contains("/v1beta") { fullPath = "\(cleanBase)/\(path)" }
            else { fullPath = "\(cleanBase)/v1beta/\(path)" }
        case .anthropic:
            if cleanBase.contains("/v1") { fullPath = "\(cleanBase)/\(path)" }
            else { fullPath = "\(cleanBase)/v1/\(path)" }
        }
        guard let url = URL(string: fullPath) else { return nil }
        var request = URLRequest(url: url)
        request.addValue("application/json", forHTTPHeaderField: "Content-Type")
        // æ·»åŠ  User-Agent ä¼ªè£…ï¼Œé˜²æ­¢è¢«æœåŠ¡ç«¯é˜²ç«å¢™æ‹¦æˆªå¯¼è‡´ SSL ä¸­æ–­
        request.addValue("Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.0 Safari/605.1.15", forHTTPHeaderField: "User-Agent")
        request.addValue("*/*", forHTTPHeaderField: "Accept")
        
        switch type {
        case .openAI, .openAIResponses: request.addValue("Bearer \(apiKey)", forHTTPHeaderField: "Authorization")
        case .gemini: request.addValue(apiKey, forHTTPHeaderField: "x-goog-api-key")
        case .anthropic:
            request.addValue(apiKey, forHTTPHeaderField: "x-api-key")
            request.addValue("2023-06-01", forHTTPHeaderField: "anthropic-version")
        case .workersAI: break // Workers AI ä¸éœ€è¦è®¤è¯
        }
        return request
    }
    
    // MARK: - Legacy Wrappers for Delegate Support
    // å¿…é¡»ä½¿ç”¨ä¼ ç»Ÿçš„ dataTask æ‰èƒ½ä¿è¯è§¦å‘ delegateï¼Œä»è€Œè·³è¿‡ TLS éªŒè¯
    
    private func legacyData(for request: URLRequest) async throws -> (Data, URLResponse) {
        return try await withCheckedThrowingContinuation { continuation in
            let task = session.dataTask(with: request) { data, response, error in
                if let error = error {
                    continuation.resume(throwing: error)
                    return
                }
                guard let data = data, let response = response else {
                    continuation.resume(throwing: URLError(.badServerResponse))
                    return
                }
                continuation.resume(returning: (data, response))
            }
            task.resume()
        }
    }

    private func performStream(request: URLRequest, continuation: AsyncThrowingStream<String, Error>.Continuation, parser: @escaping (String) -> String?) async {
        // ä½¿ç”¨ cachePolicy å¿½ç•¥ç¼“å­˜ï¼Œå¼ºåˆ¶å‘èµ·ç½‘ç»œè¯·æ±‚
        var newReq = request
        newReq.cachePolicy = .reloadIgnoringLocalAndRemoteCacheData
        
        do {
            // ç›®å‰ async/await çš„ bytes(for:) æ–¹æ³•åœ¨æŸäº› watchOS ç‰ˆæœ¬ä¸Šå¯èƒ½ä¸ä¼šæ­£ç¡®è§¦å‘ URLSessionTaskDelegate
            // å¯¼è‡´ TLS éªŒè¯æ— æ³•è·³è¿‡ã€‚
            // è™½ç„¶ legacyData å¯ä»¥ä¿è¯è§¦å‘ï¼Œä½†å®ƒä¸æ”¯æŒæµå¼ã€‚
            // è€ƒè™‘åˆ°é¡¹ç›®å¿…é¡»æ”¯æŒæµå¼è¾“å‡ºï¼Œæˆ‘ä»¬ä¼šå…ˆå°è¯•ç”¨ bytes(for:)ã€‚
            // å¦‚æœä»ç„¶æœ‰é—®é¢˜ï¼Œè¯·ç¡®ä¿ Info.plist çš„ ATS Exceptions è®¾ç½®æ­£ç¡®ã€‚
            
            let (result, response) = try await session.bytes(for: newReq)
            
            if let httpResponse = response as? HTTPURLResponse, httpResponse.statusCode != 200 {
                // continuation.yield("âŒ HTTP Error: \(httpResponse.statusCode)") // Removed to avoid duplication
                continuation.finish(throwing: URLError(.badServerResponse))
                return
            }
            
            for try await line in result.lines {
                if let text = parser(line) { continuation.yield(text) }
            }
            continuation.finish()
        } catch {
            print("âŒ Stream Error: \(error)")
            // å¦‚æœé‡åˆ° SSL é”™è¯¯ï¼Œå°è¯•é™çº§ä¸º legacyData è·å–å…¨æ–‡ï¼ˆè™½ç„¶ä¸æ˜¯æµå¼ï¼Œä½†è‡³å°‘èƒ½ç”¨ï¼‰
            if (error as NSError).domain == NSURLErrorDomain && (error as NSError).code == NSURLErrorServerCertificateUntrusted {
                 do {
                     print("âš ï¸ TLS Error detected, fallback to legacyData...")
                     let (data, _) = try await legacyData(for: newReq)
                     if let str = String(data: data, encoding: .utf8) {
                         // å°†å…¨æ–‡å½“ä½œä¸€è¡Œå¤„ç†
                         if let text = parser("data: " + str) { continuation.yield(text) } // æ¨¡æ‹Ÿæµå¼æ ¼å¼
                     }
                     continuation.finish()
                 } catch {
                     continuation.finish(throwing: error)
                 }
            } else {
                continuation.finish(throwing: error)
            }
        }
    }
}

// MARK: - Private Network Response Models
// è¿™äº›ç»“æ„ä½“æ˜¯ LLMService ç§æœ‰çš„ï¼Œä¸»çº¿ç¨‹çœ‹ä¸åˆ°ï¼Œå› æ­¤ä¸ä¼šæŠ¥é”™
private struct PrivateOpenAIModelListResponse: Codable {
    let data: [PrivateOpenAIModel]
}
private struct PrivateOpenAIModel: Codable, Identifiable {
    let id: String
}
private struct PrivateOpenAIStreamResponse: Decodable {
    let choices: [PrivateStreamChoice]
    let usage: PrivateUsage?  // v1.5: Token ç»Ÿè®¡
}
private struct PrivateStreamChoice: Decodable {
    let delta: PrivateStreamDelta
}
private struct PrivateStreamDelta: Decodable {
    let content: String?
    let reasoning_content: String? // æ™ºè°±AIç­‰æ¨¡å‹çš„æ€è€ƒå†…å®¹å­—æ®µ
}
private struct PrivateUsage: Decodable {
    let prompt_tokens: Int?
    let completion_tokens: Int?
    let total_tokens: Int?
}
private struct PrivateGeminiModelListResponse: Codable {
    let models: [PrivateGeminiModelRaw]
}
private struct PrivateGeminiModelRaw: Codable {
    let name: String
}
